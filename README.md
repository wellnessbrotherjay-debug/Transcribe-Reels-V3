# Reel Memory Engine üß†

## Project Overview
The **Reel Memory Engine** is a specialized AI dashboard designed to turn ephemeral short-form video content (Instagram Reels) into a permanent, searchable knowledge base. It functions similarly to Google's "NotebookLM," allowing users to chat with their video content and repurpose it into various assets like mind maps, slide decks, and audio summaries.

## üèó Tech Stack & Architecture

### Core System
- **Language**: Python 3.9+
- **Frontend Framework**: [Streamlit](https://streamlit.io/) (for the interactive 3-column dashboard UI)
- **Database**: [Supabase](https://supabase.com/) (PostgreSQL) - Stores transcripts, metadata, and generated summaries.

### AI & Machine Learning Components
- **Transcription Engines (Dual Mode)**:
  1.  **OpenAI Whisper (Local)** (`openai-whisper`): Runs locally on the machine using `ffmpeg`. High accuracy, supports multiple model sizes (tiny to large).
  2.  **AssemblyAI (Cloud API)** (`assemblyai`): Backup cloud-based transcription with speaker diarization support.
- **LLM / GenAI**:
  - **OpenAI GPT-4**: Used for "Chat with Reel," high-level reasoning, mind map logic extraction, and podcast script writing.
  - **OpenAI GPT-3.5-Turbo**: Used for faster tasks like briefing doc generation and data extraction.
- **Text-to-Speech (TTS)**:
  - **OpenAI Audio API** (`tts-1`): Generates the "Audio Overview" podcast-style summaries.

### Libraries & Extensions (The "Plugins")
This project creates "Studio" assets using specific Python libraries:
- **Video Processing**: `moviepy` (extracts audio from mp4), `ffmpeg` (system-level dependency).
- **Instagram Integration**: `instaloader` (downloads reels via URL/shortcode).
- **Visualization (Mind Maps)**: `graphviz` (renders DOT graph code generated by GPT-4).
- **Presentations (Decks)**: `python-pptx` (programmatically builds .pptx files from AI-generated JSON outlines).
- **Data Charts**: `streamlit` native charts (renders JSON data extracted by LLM).

## üîå APIs & Connections

The system relies on the following external connections, configured via `.env`:

1.  **OpenAI API** (`OPENAI_API_KEY`)
    - **Purpose**: Powers the Chat, Mind Map logic, Slide content generation, and TTS Audio Overview.
    - **Crucial**: The "Studio" features heavily depend on this.

2.  **Supabase** (`SUPABASE_URL`, `SUPABASE_KEY`)
    - **Purpose**: Persistence layer. Stores all transcripts so they survive app restarts.
    - **Table Structure**:
      ```sql
      table transcripts (
          id bigint primary key,
          url text unique,
          text text,
          summary text,
          metadata jsonb,
          created_at timestamp
      )
      ```

3.  **AssemblyAI** (`ASSEMBLYAI_API_KEY`)
    - **Purpose**: Alternative transcription engine (cloud usage).

## ‚öôÔ∏è Setup & Environment

### System Dependencies
- **FFmpeg**: Required for `openai-whisper` and `moviepy`.
  - Mac: `brew install ffmpeg`
  - Linux: `sudo apt install ffmpeg`

### Python Dependencies
See `requirements.txt` (implied):
```text
streamlit
openai-whisper
assemblyai
supabase
openai
moviepy
instaloader
python-pptx
graphviz
python-dotenv
```

### Environment Variables (.env)
```ini
ASSEMBLYAI_API_KEY=...
SUPABASE_URL=...
SUPABASE_KEY=...
OPENAI_API_KEY=...
```

## üöÄ Developer Notes for Enhancement
- **Vector Search**: Currently, the "Search" is a simple text match in Supabase. To make it a true "Second Brain," developers should implement `pgvector` in Supabase and generate embeddings for every transcript.
- **Multi-Modal**: The current setup extracts audio. Future enhancements could use GPT-4 Vision to analyze the video frames for visual context.
- **Chrome Extension**: A potential future step is building a Chrome Extension to "Send to Memory" directly from the Instagram browser view, rather than copy-pasting URLs.
